<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>PySpark调用自定义jar包 | VALUX</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在开发PySpark程序时通常会需要用到Java的对象，而PySpark本身也是建立在Java API之上，通过Py4j来创建JavaSparkContext。

这里有几点是需要注意的
1. Py4j只运行在driver也就是说worker目前来说引入不了第三方的jar包。因为worker结点的PySpark是没有启动Py4j的通信进程的，相应的jar包自然也加载不了。之前没有详细看这部分文档，">
<meta property="og:type" content="article">
<meta property="og:title" content="PySpark调用自定义jar包">
<meta property="og:url" content="http://valux.cn/2015/05/16/72eca5e737523eae/index.html">
<meta property="og:site_name" content="VALUX">
<meta property="og:description" content="在开发PySpark程序时通常会需要用到Java的对象，而PySpark本身也是建立在Java API之上，通过Py4j来创建JavaSparkContext。

这里有几点是需要注意的
1. Py4j只运行在driver也就是说worker目前来说引入不了第三方的jar包。因为worker结点的PySpark是没有启动Py4j的通信进程的，相应的jar包自然也加载不了。之前没有详细看这部分文档，">
<meta property="og:image" content="http://valux.cn/img/20150516103730983.jpg">
<meta property="og:updated_time" content="2015-07-31T19:48:40.030Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PySpark调用自定义jar包">
<meta name="twitter:description" content="在开发PySpark程序时通常会需要用到Java的对象，而PySpark本身也是建立在Java API之上，通过Py4j来创建JavaSparkContext。

这里有几点是需要注意的
1. Py4j只运行在driver也就是说worker目前来说引入不了第三方的jar包。因为worker结点的PySpark是没有启动Py4j的通信进程的，相应的jar包自然也加载不了。之前没有详细看这部分文档，">
  
    <link rel="alternative" href="/atom.xml" title="VALUX" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <script src="/js/jquery-2.1.4.min.js" type="text/javascript"></script>
  
  
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?6a7982ffd64704578c67a74f393d757a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
  

  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-65362177-1', 'auto');
  ga('send', 'pageview');

</script>
  

</head>
<body style="background-color: #FFF">
  <img class="bg-image" src="/img/background.jpg">
  <header id="header" class="clearfix header-fixed-top">
  <div class="nav">
    <h1>
      <a href="http://valux.cn">VALUX</a>
    </h1>
    <ul>
        
         <li>
          <a class="main-nav-link" href="/">主页</a>
          </li>
        
         <li>
          <a class="main-nav-link" href="/archives">归档</a>
          </li>
        
         <li>
          <a class="main-nav-link" href="/tags">标签</a>
          </li>
        
         <li>
          <a class="main-nav-link" href="/about">关于</a>
          </li>
        
    </ul>
  </div>
</header>

  <div id="container">
  
    <div id="article-anchor" class="article-anchor">
    <p>
        <b id="article-anchor-content-toggle" title="收起" style="cursor:pointer;">目录[-]</b>
    </p>
    <div class="article-anchor-content" id="article-anchor-content"> </div>
</div>


<script>
	$(document).ready(function(){
		var title = $("#article-title").text().trim();

		$("#article-anchor-content").append('<li><a class="article-anchor-title anchor-link" onclick="return false;" href="#" link="#article-title">'
			+title +'</a></li>');
		

		$(".article-inner").find("h2,h3,h4,h5,h6").each(function(i,item){
		    var tag = $(item).get(0).localName;
		    $(item).attr("id","anchor-h"+i);
		    $("#article-anchor-content").append('<li><a class="article-anchor-'+tag+' anchor-link" onclick="return false;" href="#" link="#anchor-h'+i+'">'
		    	+$(this).text().trim()+'</a></li>');		    
		});

		$(".article-anchor-h2").css("margin-left",0);
		$(".article-anchor-h3").css("margin-left",10);
		$(".article-anchor-h4").css("margin-left",20);
		$(".article-anchor-h5").css("margin-left",30);
		$(".article-anchor-h6").css("margin-left",40);

		$("#article-anchor-content-toggle").click(function(){
		    var text = $(this).html();
		    if(text=="目录[-]"){
		        $(this).html("目录[+]");
		        $(this).attr({"title":"展开"});
		    }else{
		        $(this).html("目录[-]");
		        $(this).attr({"title":"收起"});
		    }
		    $("#article-anchor-content").toggle();
		});

		$(".anchor-link").click(function(){
			$("html,body").animate({scrollTop: $($(this).attr("link")).offset().top - 50}, 1000);
		});

	});
</script>
  
  <div id="main" class="clearfix">
    <div class="content clearfix">      
      <article id="post-PySpark调用自定义jar包" class="article article-type-post" itemscope itemprop="blogPost">
        <h2 class="title">
          <a id="article-title" href="">PySpark调用自定义jar包</a>
        </h2>
        <div class="tag-list">
          
          <span class="article-meta">
            <a href="/2015/05/16/72eca5e737523eae/" class="article-date">
  	<time datetime="2015-05-15T16:04:31.000Z" itemprop="datePublished">2015-05-16</time>
</a>
          </span>
          
          
	<span class="article-tag">
		标签: &nbsp;
		<a class="article-tag-link" href="/tags/py4j/">py4j</a><a class="article-tag-link" href="/tags/spark/">spark</a>
	</span>
         
        </div>                    
            <div class="article-inner">
              
                <input type="hidden" class="isFancy" />
                

                          <div class="article-entry" itemprop="articleBody">
                            
                                  <p>在开发<code>PySpark</code>程序时通常会需要用到Java的对象，而<code>PySpark</code>本身也是建立在Java API之上，通过Py4j来创建<code>JavaSparkContext</code>。</p>
<p><img src="/img/20150516103730983.jpg" alt="Cached / shuffled" title="Cached / shuffled"></p>
<p>这里有几点是需要注意的</p>
<h4 id="1-_Py4j只运行在driver">1. Py4j只运行在driver</h4><p>也就是说<code>worker</code>目前来说引入不了第三方的jar包。因为<code>worker</code>结点的PySpark是没有启动Py4j的通信进程的，相应的jar包自然也加载不了。之前没有详细看这部分文档，系统设计时企图在<code>worker</code>结点利用client模式直连Hbase来获取部分数据，从而避免对整个表的JOIN操作，当然对于python来说这样的操作只有通过引入jar包来实现(不考虑thrift方式)。但是测试的jar写好之后，一直不成功，最后只有修改方案，后来才去查了官方文档。</p>
<h4 id="2-_PythonRDD_的原型是_JavaRDD[String]">2. PythonRDD 的原型是 JavaRDD[String]</h4><p>所有的经过PythonRDD传递的数据都通过BASE64编码</p>
<h4 id="3-_PySpark_中的方法和匿名函数是通过cloudpickle序列化">3. PySpark 中的方法和匿名函数是通过cloudpickle序列化</h4><p>为何函数需要被序列化，因为做<code>map</code>或者<code>flatMap</code>时，此时的函数或者lambda表达式是需要传递到各个<code>worder</code>的，如果函数里有用到闭包，<code>cloudpickle</code>也能巧妙的序列化。但是，需要传递的函数里请不要是用<code>self</code>关键字，因为传递过去后，<code>self</code>的指代关系已经不明确了。</p>
<blockquote>
<p>文档还提到<code>PythonRDD</code>的序列化是可定制的了，但是目前没这个需求，所有没测试</p>
</blockquote>
<h4 id="代码示例">代码示例</h4><p>java 测试代码， 编译生成 <code>pyspark-test.jar</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.valux.py4j;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Calculate</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sqAdd</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x * x + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Python 测试代码，放在文件 <code>driver.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> py4j.java_gateway <span class="keyword">import</span> java_import</span><br><span class="line"></span><br><span class="line">sc = SparkContext(appName=<span class="string">"Py4jTesting"</span>)</span><br><span class="line">java_import(sc._jvm, <span class="string">"org.valux.py4j.Calculate"</span>)</span><br><span class="line">func = sc._jvm.Calculate()</span><br><span class="line"><span class="keyword">print</span> func.sqAdd(<span class="number">5</span>)</span><br><span class="line"><span class="string">"""</span><br><span class="line">[OUTPUT] &gt; 26</span><br><span class="line">"""</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span><br><span class="line"> ！！！[错误用法]</span><br><span class="line"> 这里是想在每个work上调用自定义的方法，</span><br><span class="line"> 前面已经提到过PySpark目前是不支持的</span><br><span class="line">"""</span></span><br><span class="line">rdd = sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">result = rdd.map(func.sqAdd).collect()</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span><br><span class="line"> ！！！[错误用法]</span><br><span class="line"> 之前还有个错误的思路是想在work单独 import 相应的 jar	</span><br><span class="line">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(x)</span>:</span></span><br><span class="line">    java_import(sc._jvm, <span class="string">"org.valux.py4j.Calculate"</span>)</span><br><span class="line">    func = sc._jvm.Calculate()</span><br><span class="line">    func.sqAdd(x)</span><br><span class="line">rdd = sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">rdd.map(foo).collect()</span><br></pre></td></tr></table></figure>
<p>测试时，提交程序需要记得带上jar包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; bin/spar-submit --driver-class-path pyspark-test.jar driver.py</span><br></pre></td></tr></table></figure></p>
<p>这里又有一个坑，之前提交为了方便，一直都用的是 —jars 参数</p>
<blockquote>
<p>—driver-class-path 附加的 jar 只会在 <code>driver</code>引入<br>—jars 附加的jar会在所有<code>worker</code>引入</p>
</blockquote>
<p>帮助文档里面还提到 </p>
<blockquote>
<p>—jars Comma-separated list of local jars to include on the driver and executor classpaths.</p>
</blockquote>
<p>所有就偷个懒用了 —jars ，结果一直报如下错误:</p>
<blockquote>
<p>py4j.protocol.Py4JError: Trying to call a package.</p>
</blockquote>
<p>测试了好久终于解决了</p>
<h4 id="参考文档">参考文档</h4><blockquote>
<p><a href="https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals</a></p>
</blockquote>

                                    
                          </div>
                          
            </div>   
             
              <blockquote class="post-copyright">
	<p>作者： <a target="_blank" href="http://valux.cn">VALUX</a></p>
	<p>链接： <a target="_blank" href="http://valux.cn/2015/05/16/72eca5e737523eae/">http://valux.cn/2015/05/16/72eca5e737523eae/</a></p>
	<p> 
		本文基于<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/2.5/cn/">署名-非商业性使用-相同方式共享 2.5</a>中国大陆许可协议发布，转载请保留本文的署名
        <a target="_blank" href="http://valux.cn">Valux</a> 和 <a target="_blank" href="http://valux.cn/2015/05/16/72eca5e737523eae/">原文链接</a>
	</p>
</blockquote>
            

            
      </article>

      
        
<nav id="article-nav">
  
  <span id="article-nav-newer">
    <strong class="article-nav-caption">上一篇:</strong>
    <a href="/2015/06/02/13462a894cbd366e/"  class="article-nav-link-wrap">      
      <span class="article-nav-title">
        
          高性能IO模型浅析
        
      </span>
    </a>
  </span>
  

  
  <span id="article-nav-older" >
    <strong class="article-nav-caption">下一篇:</strong>
    <a href="/2015/05/12/5d61b98314663d23/" class="article-nav-link-wrap">      
      <span class="article-nav-title">PySpark操作HBase时设置scan参数</span>      
    </a>
  </span>
  
</nav>

            
    
      
        <!-- UY BEGIN -->
<div id="uyan_frame" style="margin-top:25px;"></div>
<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=1970884"></script>
<!-- UY END -->      
      
    </div>
  
  </div>
  
  <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; VALUX 2015 
        | BLOG <a href="https://hexo.io/" target="_blank" style="color: #bbb;"> Hexo</a>
        | THEMES <a href="https://github.com/SerhoLiu/serholiu.com" target="_blank" style="color: #bbb;"> MiniAkio</a>        
    	</div>
      	<a href="javascript:$('html,body').animate({scrollTop: $('html').offset().top }, 1000);" class="to-top">TOP</a>
    </div>
  </div>
</footer>


</div>


</body>
</html>